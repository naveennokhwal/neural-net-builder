# ğŸ”§ Neural Network Framework from Scratch (Python)

A fully customizable deep learning framework built from scratch in Python, featuring a core auto-differentiation engine (`Value`) for training neural networks. This project is designed for learning and rapid experimentationâ€”users can define any feedforward architecture without relying on external ML libraries like PyTorch or TensorFlow.

---

## ğŸ’¡ Why I Created This

The goal was to:
- Deeply understand how neural networks work internally.
- Gain hands-on experience with forward and backward propagation.
- Build a clean, reusable training and evaluation pipeline.
- Allow easy extension for custom models or datasets.

---

## âœ¨ Key Highlights

- âš™ï¸ **Custom `Value` class** for forward and backward passes  
- ğŸ§  Build **any neural network architecture**â€”you define the layers  
- ğŸ”„ Full support for gradient computation using backpropagation  
- ğŸ“Š Includes an **example MLP model** trained on the Iris dataset  
- ğŸ—‚ï¸ Modular and well-documented codebase  
- âœ… No deep learning libraries required

---

## ğŸ“ Project Structure
```
neural-network-builder/
â”œâ”€â”€ data/ # Raw and processed datasets
â”‚ â”œâ”€â”€ raw/ # Original data files
â”‚ â””â”€â”€ processed/ # Cleaned and preprocessed data
â”œâ”€â”€ src/ # Source code for the neural network
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ layers.py # Definitions of custom neural network layers
â”‚ â”œâ”€â”€ model.py # Model architecture built using layers
â”‚ â”œâ”€â”€ train.py # Script to train the model
â”‚ â”œâ”€â”€ evaluate.py # Script to evaluate the trained model
â”‚ â”œâ”€â”€ graph.py # Code to visualize the computational graph
â”‚ â”œâ”€â”€ Value.py # Custom data type to enable flexible tensor operations
â”‚ â””â”€â”€ utils.py # Helper functions (e.g., data loading, preprocessing, metrics)
â”œâ”€â”€ notebooks/ # Jupyter notebooks for experiments and exploration
â”‚ â””â”€â”€ exploration.ipynb
â”œâ”€â”€ docs/ # Project documentation and usage guides
â”‚ â””â”€â”€ usage_guide.md
â”œâ”€â”€ requirements.txt # List of Python dependencies
â”œâ”€â”€ README.md # Project overview and setup instructions
â””â”€â”€ .gitignore # Specifies files/folders to be ignored by Git
```
---

## ğŸ§  About the `Value` Class

At the heart of this framework is `value.py`, which implements a minimal autograd engine:

- Enables building and training neural networks **from scratch**
- Each mathematical operation tracks its **computation graph**
- Automatic gradient calculation via **backpropagation**
- Inspired by PyTorchâ€™s dynamic computation graph (e.g., `torch.Tensor` with `.backward()`)

You can build your entire model on top of `Value`, making it highly extensible and educational.

---

## ğŸ§ª Example: Iris Classification (MLP)

Weâ€™ve included a small demo model (`model.py`) that classifies the Iris dataset using a simple MLP.

> ğŸ“Œ **Note**: This is **only a demo** to showcase how the code works.  
> You can plug in any dataset and define your own neural network architecture with any number of layers and neurons.

---

## ğŸ“¦ Installation

1. Clone the repo:
   ```bash
   git clone https://github.com/naveennokhwal/neural-network-builder.git
   cd neural-network-builder
   ```
Install dependencies:
  ```bash
    pip install -r requirements.txt
  ```
âš™ï¸ How to Use
To train the example model:
  ```bash
    python train.py
  ```
To evaluate the saved model:
  ```bash
    python evaluate.py
  ```
### To build your own network:
- Edit model.py to define a new architecture.
- Tweak train.py for dataset/training config.
- Done!

### For full instructions, see `docs\usage_guide.md`
