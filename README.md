# ðŸ”§ Neural Network Framework from Scratch (Python)

A fully customizable deep learning framework built from scratch in Python, featuring a core auto-differentiation engine (`Value`) for training neural networks. This project is designed for learning and rapid experimentationâ€”users can define any feedforward architecture without relying on external ML libraries like PyTorch or TensorFlow.

---

## ðŸ’¡ Why I Created This

The goal was to:
- Deeply understand how neural networks work internally.
- Gain hands-on experience with forward and backward propagation.
- Build a clean, reusable training and evaluation pipeline.
- Allow easy extension for custom models or datasets.

---

## âœ¨ Key Highlights

- âš™ï¸ **Custom `Value` class** for forward and backward passes  
- ðŸ§  Build **any neural network architecture**â€”you define the layers  
- ðŸ”„ Full support for gradient computation using backpropagation  
- ðŸ“Š Includes an **example MLP model** trained on the Iris dataset  
- ðŸ—‚ï¸ Modular and well-documented codebase  
- âœ… No deep learning libraries required

---

## ðŸ“ Project Structure

neural-network-framework/
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ processed/
â”‚ â””â”€â”€ Iris_noindex.csv # Example dataset
â”‚
â”œâ”€â”€ value.py # Core: Auto-diff engine (Value class)
â”œâ”€â”€ model.py # Example: Define your own architecture here
â”œâ”€â”€ train.py # Training loop (edit to match your design)
â”œâ”€â”€ evaluate.py # Evaluation script
â”œâ”€â”€ utils.py # Data preprocessing and evaluation helpers
â”œâ”€â”€ requirements.txt # Required dependencies
â”œâ”€â”€ README.md # Project overview (this file)
â””â”€â”€ usage_guide.md # Full usage + customization instructions

---

## ðŸ§  About the `Value` Class

At the heart of this framework is `value.py`, which implements a minimal autograd engine:

- Enables building and training neural networks **from scratch**
- Each mathematical operation tracks its **computation graph**
- Automatic gradient calculation via **backpropagation**
- Inspired by PyTorchâ€™s dynamic computation graph (e.g., `torch.Tensor` with `.backward()`)

You can build your entire model on top of `Value`, making it highly extensible and educational.

---

## ðŸ§ª Example: Iris Classification (MLP)

Weâ€™ve included a small demo model (`model.py`) that classifies the Iris dataset using a simple MLP.

> ðŸ“Œ **Note**: This is **only a demo** to showcase how the code works.  
> You can plug in any dataset and define your own neural network architecture with any number of layers and neurons.

---

## ðŸ“¦ Installation

1. Clone the repo:
   ```bash
   git clone https://github.com/your-username/neural-network-framework.git
   cd neural-network-framework
   ```
Install dependencies:
  ```bash
    pip install -r requirements.txt
  ```
âš™ï¸ How to Use
To train the example model:
  ```bash
    python train.py
  ```
To evaluate the saved model:
  ```bash
    python evaluate.py
  ```
To build your own network:

Edit model.py to define a new architecture.

Tweak train.py for dataset/training config.

Done!

For full instructions, see usage_guide.md

ðŸ“š Requirements
pandas>=1.5.0
(Note: No need for NumPy or PyTorch)
